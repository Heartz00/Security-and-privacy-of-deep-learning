{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY5pfzaGGNhk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d566dd7f-820f-4c96-fc66-ca5929c7c0fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting cleverhans\n",
            "  Cloning https://github.com/tensorflow/cleverhans.git to /tmp/pip-install-fa47tsjr/cleverhans_82ea0f474ef048afbb86985d3d45f4e5\n",
            "  Running command git clone -q https://github.com/tensorflow/cleverhans.git /tmp/pip-install-fa47tsjr/cleverhans_82ea0f474ef048afbb86985d3d45f4e5\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.3.7)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (from cleverhans) (2.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (3.2.2)\n",
            "Requirement already satisfied: mnist in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.2.0)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.10)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cleverhans) (1.15.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (1.4.4)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans) (4.1.1)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (4.4.2)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (0.1.7)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans) (1.5.0)\n",
            "Building wheels for collected packages: cleverhans\n",
            "Installing collected packages: cleverhans\n",
            "  Attempting uninstall: cleverhans\n",
            "    Found existing installation: cleverhans 3.0.1\n",
            "    Uninstalling cleverhans-3.0.1:\n",
            "      Successfully uninstalled cleverhans-3.0.1\n",
            "Successfully installed cleverhans-4.0.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: advertorch in /usr/local/lib/python3.7/dist-packages (0.2.3)\n"
          ]
        }
      ],
      "source": [
        "#Install the dependencies\n",
        "!pip install git+https://github.com/tensorflow/cleverhans.git#egg=cleverhans\n",
        "!pip install advertorch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/CNOCycle/cleverhans.git@feature/tf2.x"
      ],
      "metadata": {
        "id": "MQz8XbhgFTju",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d922f3fa-650b-44fe-caa5-b4d6d5464f1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/CNOCycle/cleverhans.git@feature/tf2.x\n",
            "  Cloning https://github.com/CNOCycle/cleverhans.git (to revision feature/tf2.x) to /tmp/pip-req-build-1kwkjrys\n",
            "  Running command git clone -q https://github.com/CNOCycle/cleverhans.git /tmp/pip-req-build-1kwkjrys\n",
            "  Running command git checkout -b feature/tf2.x --track origin/feature/tf2.x\n",
            "  Switched to a new branch 'feature/tf2.x'\n",
            "  Branch 'feature/tf2.x' set up to track remote branch 'feature/tf2.x' from 'origin'.\n",
            "Requirement already satisfied: nose in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (1.3.7)\n",
            "Requirement already satisfied: pycodestyle in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (2.9.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (1.7.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (3.2.2)\n",
            "Requirement already satisfied: mnist~=0.2 in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (0.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (1.21.6)\n",
            "Requirement already satisfied: tensorflow-probability in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (0.16.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from cleverhans==3.0.1) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans==3.0.1) (3.0.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans==3.0.1) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans==3.0.1) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->cleverhans==3.0.1) (2.8.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->cleverhans==3.0.1) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->cleverhans==3.0.1) (1.15.0)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.5.0)\n",
            "Requirement already satisfied: gast>=0.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (0.4.0)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (1.3.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from tensorflow-probability->cleverhans==3.0.1) (4.4.2)\n",
            "Building wheels for collected packages: cleverhans\n",
            "  Building wheel for cleverhans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cleverhans: filename=cleverhans-3.0.1-py3-none-any.whl size=254394 sha256=323abcd00807e03caede951c83f821994b20e50b55e6f982853c401d42a2a140\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-fd6hsm6r/wheels/7b/f7/6b/d754a65b70ab265387116e0a3b9c7bdb7adedc4e7afd04815f\n",
            "Successfully built cleverhans\n",
            "Installing collected packages: cleverhans\n",
            "  Attempting uninstall: cleverhans\n",
            "    Found existing installation: cleverhans 4.0.0\n",
            "    Uninstalling cleverhans-4.0.0:\n",
            "      Successfully uninstalled cleverhans-4.0.0\n",
            "Successfully installed cleverhans-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==1.14"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 973
        },
        "id": "jkdzP4rLrs9i",
        "outputId": "f0fdfd7d-2e33-4ccf-ee01-33b9c08eaf43"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow==1.14\n",
            "  Downloading tensorflow-1.14.0-cp37-cp37m-manylinux1_x86_64.whl (109.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 109.3 MB 31 kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.50.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.3.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.21.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.14.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 6.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.4.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.8.1)\n",
            "Collecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0\n",
            "  Downloading tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488 kB)\n",
            "\u001b[K     |████████████████████████████████| 488 kB 62.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.37.1)\n",
            "Collecting tensorboard<1.15.0,>=1.14.0\n",
            "  Downloading tensorboard-1.14.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 45.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.14) (2.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.14) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.4.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (57.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (4.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<1.15.0,>=1.14.0->tensorflow==1.14) (3.10.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.6->tensorflow==1.14) (1.5.2)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.7 requires tensorflow>=2.0.0, but you have tensorflow 1.14.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-applications-1.0.8 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "fPKcarELrsxo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "metadata": {
        "id": "ubtJrSczGSPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixmWRNyDIK0w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ea216c8-20be-4233-a50b-5f43e3ac5c1e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.7/dist-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/cleverhans/utils_tf.py:345: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import unicode_literals\n",
        "\n",
        "import warnings\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch import optim\n",
        "from torch.autograd import Variable\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from cleverhans.compat import flags\n",
        "from cleverhans.train import train\n",
        "from cleverhans.dataset import MNIST\n",
        "from cleverhans.utils import AccuracyReport\n",
        "from cleverhans.utils_tf import model_eval\n",
        "\n",
        "#Attack on PyTorch\n",
        "from cleverhans.future.torch.attacks.fast_gradient_method import fast_gradient_method\n",
        "\n",
        "#advertorch attacks\n",
        "#from advertorch.attacks import CarliniWagnerL2Attack"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a simple network\n",
        "class LeNet5(torch.nn.Module):          \n",
        "     \n",
        "    def __init__(self):     \n",
        "        super(LeNet5, self).__init__()\n",
        "        self.conv1 = torch.nn.Conv2d(1, 6, 5, padding=2)\n",
        "        self.conv2 = torch.nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)   \n",
        "        self.fc2 = nn.Linear(120, 84)       \n",
        "        self.fc3 = nn.Linear(84, 10)    \n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))  \n",
        "        x = F.max_pool2d(x, 2) \n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return F.log_softmax(x,dim=-1)"
      ],
      "metadata": {
        "id": "O-5iqv35LWvm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_y20tJoHYAB"
      },
      "outputs": [],
      "source": [
        "FLAGS = flags.FLAGS\n",
        "NB_EPOCHS = 2\n",
        "BATCH_SIZE = 128\n",
        "LEARNING_RATE = .001\n",
        "\n",
        "#Training the Network\n",
        "def trainTorch(torch_model, train_loader, test_loader,\n",
        "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE, optimizer=None):\n",
        "\n",
        "    train_loss = []\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    step = 0\n",
        "    for _epoch in range(nb_epochs):\n",
        "      for xs, ys in train_loader:\n",
        "        xs, ys = Variable(xs), Variable(ys)\n",
        "        if torch.cuda.is_available():\n",
        "          xs, ys = xs.cuda(), ys.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        preds = torch_model(xs)\n",
        "        # print(\"HI\")\n",
        "        loss = F.nll_loss(preds, ys)\n",
        "        # print(\"HADSFSDF\")\n",
        "        loss.backward()  # calc gradients\n",
        "        train_loss.append(loss.data.item())\n",
        "        optimizer.step()  # update gradients\n",
        "\n",
        "        preds_np = preds.cpu().detach().numpy()\n",
        "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
        "        total += train_loader.batch_size\n",
        "        step += 1\n",
        "        if total % 1000 == 0:\n",
        "          acc = float(correct) / total\n",
        "          print('[%s] Training accuracy: %.2f%%' % (step, acc * 100))\n",
        "          total = 0\n",
        "          correct = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0To3gEyID4g"
      },
      "outputs": [],
      "source": [
        "#Evaluate results on clean data\n",
        "def evalClean(model1=None, test_loader=None):\n",
        "    print(\"Evaluating single model results on clean data\")\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "      model1.eval()\n",
        "      for xs, ys in test_loader:\n",
        "        xs, ys = Variable(xs), Variable(ys)\n",
        "        if torch.cuda.is_available():\n",
        "          xs, ys = xs.cuda(), ys.cuda()\n",
        "        preds1 = model1(xs)\n",
        "        preds_np1 = preds1.cpu().detach().numpy()\n",
        "        finalPred = np.argmax(preds_np1, axis=1)\n",
        "        correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
        "        total += len(xs)\n",
        "    acc = float(correct) / total\n",
        "    print('Clean accuracy: %.2f%%' % (acc * 100))\n",
        "\n",
        "#Evaluate results on adversarially perturbed \n",
        "def evalAdvAttack(fgsm_model=None, test_loader=None):\n",
        "    print(\"Evaluating single model results on adv data\")\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    fgsm_model.eval()\n",
        "    for xs, ys in test_loader:\n",
        "      if torch.cuda.is_available():\n",
        "        xs, ys = xs.cuda(), ys.cuda()\n",
        "      #pytorch fast gradient method\n",
        "      xs = fast_gradient_method(fgsm_model, xs, eps=0.3, norm=np.inf, clip_min=0., clip_max=1.)\n",
        "      # xs = fast_gradient_method(fgsm_model, xs, eps=0.1, norm=np.inf)\n",
        "      xs, ys = Variable(xs), Variable(ys)\n",
        "      preds1 = fgsm_model(xs)\n",
        "      preds_np1 = preds1.cpu().detach().numpy()\n",
        "      finalPred = np.argmax(preds_np1, axis=1)\n",
        "      correct += (finalPred == ys.cpu().detach().numpy()).sum()\n",
        "      total += test_loader.batch_size\n",
        "    acc = float(correct) / total\n",
        "    print('Adv accuracy: {:.3f}％'.format(acc * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fKtURoV6TJDp"
      },
      "outputs": [],
      "source": [
        "#Adversarial Training\n",
        "def advTrain(torch_model, train_loader, test_loader,\n",
        "        nb_epochs=NB_EPOCHS, batch_size=BATCH_SIZE, train_end=-1, test_end=-1, learning_rate=LEARNING_RATE):\n",
        "    optimizer = optim.Adam(torch_model.parameters(), lr=learning_rate)\n",
        "    train_loss = []\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    totalAdv = 0\n",
        "    correctAdv = 0\n",
        "    step = 0\n",
        "    # breakstep = 0\n",
        "    for _epoch in range(nb_epochs):\n",
        "      for xs, ys in train_loader:\n",
        "        #Normal Training\n",
        "        xs, ys = Variable(xs), Variable(ys)\n",
        "        if torch.cuda.is_available():\n",
        "          xs, ys = xs.cuda(), ys.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        preds = torch_model(xs)\n",
        "        loss = F.nll_loss(preds, ys)\n",
        "        loss.backward()  # calc gradients\n",
        "        train_loss.append(loss.data.item())\n",
        "        optimizer.step()  # update gradients\n",
        "        preds_np = preds.cpu().detach().numpy()\n",
        "        correct += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
        "        total += train_loader.batch_size\n",
        "\n",
        "        #Adversarial Training\n",
        "        xs = fast_gradient_method(torch_model, xs, eps=0.3, norm=np.inf, clip_min=0., clip_max=1.)\n",
        "        xs, ys = Variable(xs), Variable(ys)\n",
        "        if torch.cuda.is_available():\n",
        "            xs, ys = xs.cuda(), ys.cuda()\n",
        "        optimizer.zero_grad()\n",
        "        preds = torch_model(xs)\n",
        "        loss = F.nll_loss(preds, ys)\n",
        "        loss.backward()  # calc gradients\n",
        "        train_loss.append(loss.data.item())\n",
        "        optimizer.step()  # update gradients\n",
        "        preds_np = preds.cpu().detach().numpy()\n",
        "        correctAdv += (np.argmax(preds_np, axis=1) == ys.cpu().detach().numpy()).sum()\n",
        "        totalAdv += train_loader.batch_size\n",
        "        \n",
        "        step += 1\n",
        "        if total % 1000 == 0:\n",
        "          acc = float(correct) / total\n",
        "          print('[%s] Clean Training accuracy: %.2f%%' % (step, acc * 100))\n",
        "          total = 0\n",
        "          correct = 0\n",
        "          accAdv = float(correctAdv) / totalAdv\n",
        "          print('[%s] Adv Training accuracy: %.2f%%' % (step, accAdv * 100))\n",
        "          totalAdv = 0\n",
        "          correctAdv = 0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize model and data loader\n",
        "model1 = LeNet5()\n",
        "if torch.cuda.is_available():\n",
        "  model1 = model1.cuda()\n",
        "nb_epochs = 4\n",
        "batch_size = 128\n",
        "learning_rate = 0.001\n",
        "train_end = -1\n",
        "test_end = -1\n",
        "report = AccuracyReport\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=True, download=True,\n",
        "                    transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('data', train=False, transform=transforms.ToTensor()),\n",
        "    batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "75gH3-YKIsTX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Training the model\n",
        "print(\"Training Model\")\n",
        "optimizer = optim.Adam(model1.parameters(), lr=learning_rate)\n",
        "trainTorch(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate, optimizer = optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fsSV91TIv0G",
        "outputId": "e5755e79-69e5-47d6-e176-4083897d9169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Model\n",
            "[125] Training accuracy: 72.82%\n",
            "[250] Training accuracy: 92.38%\n",
            "[375] Training accuracy: 94.76%\n",
            "[500] Training accuracy: 96.05%\n",
            "[625] Training accuracy: 96.36%\n",
            "[750] Training accuracy: 97.14%\n",
            "[875] Training accuracy: 97.08%\n",
            "[1000] Training accuracy: 97.27%\n",
            "[1125] Training accuracy: 97.84%\n",
            "[1250] Training accuracy: 97.79%\n",
            "[1375] Training accuracy: 97.99%\n",
            "[1500] Training accuracy: 98.00%\n",
            "[1625] Training accuracy: 98.24%\n",
            "[1750] Training accuracy: 98.31%\n",
            "[1875] Training accuracy: 98.36%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Evaluation\n",
        "evalClean(model1, test_loader)\n",
        "evalAdvAttack(model1, test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1TILA-aysNa5",
        "outputId": "7e2a5b5b-9062-4ffc-e24c-4bbb101f41e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating single model results on clean data\n",
            "Clean accuracy: 97.98%\n",
            "Evaluating single model results on adv data\n",
            "Adv accuracy: 2.957％\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Training on Adversarial Samples\")\n",
        "advTrain(model1, train_loader, test_loader, nb_epochs, batch_size, train_end, test_end, learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUSLM2DxtYO5",
        "outputId": "d1b998ee-6911-4baa-8950-cddb296d3757"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training on Adversarial Samples\n",
            "[125] Clean Training accuracy: 97.04%\n",
            "[125] Adv Training accuracy: 35.41%\n",
            "[250] Clean Training accuracy: 97.59%\n",
            "[250] Adv Training accuracy: 58.71%\n",
            "[375] Clean Training accuracy: 97.58%\n",
            "[375] Adv Training accuracy: 67.29%\n",
            "[500] Clean Training accuracy: 97.96%\n",
            "[500] Adv Training accuracy: 75.28%\n",
            "[625] Clean Training accuracy: 98.19%\n",
            "[625] Adv Training accuracy: 82.05%\n",
            "[750] Clean Training accuracy: 98.10%\n",
            "[750] Adv Training accuracy: 84.31%\n",
            "[875] Clean Training accuracy: 98.28%\n",
            "[875] Adv Training accuracy: 86.57%\n",
            "[1000] Clean Training accuracy: 98.15%\n",
            "[1000] Adv Training accuracy: 86.32%\n",
            "[1125] Clean Training accuracy: 98.58%\n",
            "[1125] Adv Training accuracy: 87.50%\n",
            "[1250] Clean Training accuracy: 98.70%\n",
            "[1250] Adv Training accuracy: 88.00%\n",
            "[1375] Clean Training accuracy: 98.56%\n",
            "[1375] Adv Training accuracy: 88.52%\n",
            "[1500] Clean Training accuracy: 98.48%\n",
            "[1500] Adv Training accuracy: 89.19%\n",
            "[1625] Clean Training accuracy: 98.65%\n",
            "[1625] Adv Training accuracy: 89.24%\n",
            "[1750] Clean Training accuracy: 98.72%\n",
            "[1750] Adv Training accuracy: 89.83%\n",
            "[1875] Clean Training accuracy: 98.84%\n",
            "[1875] Adv Training accuracy: 90.76%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}